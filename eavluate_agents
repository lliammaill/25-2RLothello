# evaluate_agents.py
# (ê²½ë¡œ: /Users/liam/Desktop/Othello/evaluate_agents.py)

import numpy as np
import pickle
import os
import torch
from othello_env_agent import OthelloEnv, QLearningAgent, DQNAgent, DQNetwork 

# ============================================================
# ë¡œì»¬ í™˜ê²½ ì„¤ì •
# ============================================================
PROJECT_DIR = '/Users/liam/Desktop/Othello'
Q_TABLE_LOAD_PATH = os.path.join(PROJECT_DIR, "q_table_othello.pkl")
MODEL_LOAD_PATH = os.path.join(PROJECT_DIR, "dqn_othello_model.pth")

# M1/MPS ë””ë°”ì´ìŠ¤ ì„¤ì • (DQN ë¡œë“œ ì‹œ í•„ìš”)
if torch.backends.mps.is_available():
    DEVICE = torch.device("mps")
elif torch.cuda.is_available():
    DEVICE = torch.device("cuda")
else:
    DEVICE = torch.device("cpu")


# ============================================================
# 1ï¸âƒ£ Agent ë¡œë“œ í•¨ìˆ˜
# ============================================================
def load_q_agent(env):
    """Q-Tableì„ ë¡œë“œí•˜ì—¬ QLearningAgentë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        with open(Q_TABLE_LOAD_PATH, 'rb') as f:
            q_table_data = pickle.load(f)
        
        # QLearningAgent ê°ì²´ ìƒì„± (epsilon=0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ íƒìš•ì ìœ¼ë¡œ ë§Œë“¦)
        q_agent = QLearningAgent(env, epsilon=0.0)
        
        # ë¡œë“œëœ dict ë°ì´í„°ë¥¼ defaultdictë¡œ ë‹¤ì‹œ ë³€í™˜í•˜ì—¬ í• ë‹¹
        for state_key, q_values in q_table_data.items():
            q_agent.q_table[state_key] = q_values
            
        print(f"âœ… Q-Learning Agent ë¡œë“œ ì„±ê³µ. (Q-Table í¬ê¸°: {len(q_agent.q_table)})")
        return q_agent
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: Q-Table íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. Q-Learning Agentë¥¼ í•™ìŠµ(train_q_learning.py)í•˜ì„¸ìš”.")
        return None
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: Q-Learning Agent ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


def load_dqn_agent(env):
    """ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•˜ì—¬ DQNAgentë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        dqn_agent = DQNAgent(env, epsilon=0.0)
        
        # í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
        dqn_agent.q_net.load_state_dict(torch.load(MODEL_LOAD_PATH, map_location=DEVICE))
        dqn_agent.q_net.eval() # í‰ê°€ ëª¨ë“œ ì„¤ì • (Dropout ë“±ì„ ë¹„í™œì„±í™”)
        
        print("âœ… DQN Agent ë¡œë“œ ì„±ê³µ.")
        return dqn_agent
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: DQN ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. DQN Agentë¥¼ í•™ìŠµ(train_dqn.py)í•˜ì„¸ìš”.")
        return None
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: DQN Agent ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None


# ============================================================
# 2ï¸âƒ£ ëŒ€ê²° í•¨ìˆ˜
# ============================================================
def play_game(env, player1, player2, starting_player=1):
    """ë‘ ì—ì´ì „íŠ¸ ê°„ì˜ ê²Œì„ì„ í”Œë ˆì´í•˜ê³  ìŠ¹ì(1 ë˜ëŠ” 2)ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    
    # gym resetì€ (state, info)ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ, ìƒíƒœ(state)ë§Œ ë°›ìŠµë‹ˆë‹¤.
    state, _ = env.reset() 

    current_player_id = starting_player
    
    # í‘(1)ê³¼ ë°±(2) ì—ì´ì „íŠ¸ ë§¤í•‘
    agents = {1: player1, 2: player2}
    
    terminated = False
    truncated = False
    
    while not (terminated or truncated):
        current_agent = agents[current_player_id]
        env.current_player = current_player_id # í™˜ê²½ì˜ í˜„ì¬ í”Œë ˆì´ì–´ ì„¤ì •
        
        valid_moves = env.valid_moves()
        
        if not valid_moves:
            # ë‘˜ ê³³ì´ ì—†ìœ¼ë©´ ìƒëŒ€ë°©ì—ê²Œ í„´ì„ ë„˜ê¹€
            opponent_id = 3 - current_player_id
            env.current_player = opponent_id
            
            # ìƒëŒ€ë°©ë„ ë‘˜ ê³³ì´ ì—†ìœ¼ë©´ ê²Œì„ ì¢…ë£Œ
            if not env.valid_moves():
                env.game_over = True
                terminated = True
                break
            
            # ìƒëŒ€ë°©ì—ê²Œ í„´ì„ ë„˜ê¹€
            current_player_id = opponent_id
            continue

        action = current_agent.act(state, valid_moves)
        
        # â­â­ 5ê°€ì§€ ë°˜í™˜ ê°’ ë°›ê¸° (next_state, reward, terminated, truncated, info) â­â­
        next_state, reward, terminated, truncated, _ = env.step(action)
        
        state = next_state
        current_player_id = 3 - current_player_id
        
    # ê²Œì„ ì¢…ë£Œ í›„ ìŠ¹ì ê²°ì •
    black_score = np.sum(env.board == 1)
    white_score = np.sum(env.board == 2)
    
    if black_score > white_score:
        return 1 # í‘ ìŠ¹ë¦¬
    elif white_score > black_score:
        return 2 # ë°± ìŠ¹ë¦¬
    else:
        return 0 # ë¬´ìŠ¹ë¶€


# ============================================================
# 3ï¸âƒ£ ë©”ì¸ ì‹¤í–‰ ë£¨í”„
# ============================================================
if __name__ == '__main__':
    env = OthelloEnv()
    
    q_agent = load_q_agent(env)
    dqn_agent = load_dqn_agent(env)

    if q_agent is None or dqn_agent is None:
        print("ì—ì´ì „íŠ¸ ë¡œë“œ ì‹¤íŒ¨. ëŒ€ê²°ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        N_GAMES = 100
        dqn_wins = 0
        q_wins = 0
        draws = 0
        
        print(f"\n======== âš”ï¸ DQN vs Q-Learning ëŒ€ê²° ì‹œì‘ (ì´ {N_GAMES}íŒ) ========")
        print("DQN(1) vs QL(2)ì€ 50íŒ, QL(1) vs DQN(2)ì€ 50íŒ ì§„í–‰í•©ë‹ˆë‹¤.")

        for i in range(N_GAMES):
            # 50íŒì€ DQNì´ ì„ ê³µ(1), QLì´ í›„ê³µ(2)
            if i < N_GAMES / 2:
                player1, player2 = dqn_agent, q_agent
                start_id = 1
                p1_name, p2_name = "DQN", "QL"
            # ë‚˜ë¨¸ì§€ 50íŒì€ QLì´ ì„ ê³µ(1), DQNì´ í›„ê³µ(2)
            else:
                player1, player2 = q_agent, dqn_agent
                start_id = 1
                p1_name, p2_name = "QL", "DQN"
                
            winner = play_game(env, player1, player2, starting_player=start_id)

            if winner == 1:
                if p1_name == "DQN":
                    dqn_wins += 1
                else:
                    q_wins += 1
            elif winner == 2:
                if p2_name == "DQN":
                    dqn_wins += 1
                else:
                    q_wins += 1
            else:
                draws += 1
                
            if (i + 1) % 10 == 0:
                print(f"[{i+1}/{N_GAMES} ê²Œì„ ì™„ë£Œ] DQN ìŠ¹: {dqn_wins}, QL ìŠ¹: {q_wins}, ë¬´ìŠ¹ë¶€: {draws}")


        # ìµœì¢… ê²°ê³¼ ì¶œë ¥
        total_wins = dqn_wins + q_wins
        dqn_win_rate = (dqn_wins / total_wins) * 100 if total_wins > 0 else 0
        ql_win_rate = (q_wins / total_wins) * 100 if total_wins > 0 else 0
        
        print("\n\n===================== ğŸ† ìµœì¢… ê²°ê³¼ ğŸ† =====================")
        print(f"ì´ ê²Œì„ ìˆ˜: {N_GAMES} (ì„ í›„ê³µ êµëŒ€ í¬í•¨)")
        print(f"DQN Agent ìŠ¹ë¦¬: {dqn_wins}íšŒ ({dqn_win_rate:.2f}%)")
        print(f"Q-Learning Agent ìŠ¹ë¦¬: {q_wins}íšŒ ({ql_win_rate:.2f}%)")
        print(f"ë¬´ìŠ¹ë¶€: {draws}íšŒ")
        print("==========================================================")
